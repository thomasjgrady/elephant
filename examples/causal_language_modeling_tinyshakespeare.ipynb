{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25bb70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elephant.neurons import *\n",
    "from elephant.synapses import *\n",
    "from elephant import HAM\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68c4c787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#vocab  = 65\n",
      "#tokens = 1.1154M\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.expanduser('~/data/tinyshakespeare/input.txt')\n",
    "with open(data_path, 'r') as f:\n",
    "    text = f.read()\n",
    "vocab = set(text)\n",
    "n_vocab = len(vocab)\n",
    "char_to_token = { c: i for i, c in enumerate(sorted(list(vocab))) }\n",
    "token_to_char = { i: c for c, i in char_to_token.items() }\n",
    "data = np.array([char_to_token[c] for c in text], dtype=np.uint8)\n",
    "n_data = len(data)\n",
    "\n",
    "print(f'#vocab  = {n_vocab}')\n",
    "print(f'#tokens = {n_data/1e6:.4f}M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6e299da",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_token = 64\n",
    "n_embed = 128\n",
    "n_heads = 16\n",
    "n_proj  = n_embed\n",
    "beta_attn = 10.0\n",
    "beta_mem = 10.0\n",
    "device = torch.device('cuda')\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "956e7771",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nn.Embedding(n_vocab, n_embed, device=device, dtype=dtype)\n",
    "decoder = nn.Linear(n_embed, n_vocab, device=device, dtype=dtype)\n",
    "encoder.weight = decoder.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a7bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_enc = set(itertools.chain(encoder.parameters(), decoder.parameters()))\n",
    "optim_enc = torch.optim.AdamW(params_enc, lr=1e-2, weight_decay=1e-4)\n",
    "optim_enc.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3e6030d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1395b613e7a4369bf8d5f3f556852d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bff07e586274972b41da0681f0de07a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1331a8578184b9994f8522009b05a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334d1b6dbb6646a48afa5367aef4f4d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f326c2aef8a4be18bfef760106add98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27acdee90edc47759f2f8c91cb9e1551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99603847f47c4ebaa619a2d88498aa51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbf744ac3a547949eb3fd5a70d1b31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90450e22bc3b4b048c34958867daf7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c87231d47c47f1aa3c9c9d59e4aa4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034c671f36b14db3ad896ed5357b0b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cdd7c74c654c5d9a264da680ed7497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f612e3f3d4fe45d8b5d48e39d7282c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5579421a707f44848a2cfb4cb7a24fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f598a82151c54b62975213d3264151de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19f610c548743ecae11e0541589b9c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4839f6e4f01d4352959787f42a4ac1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd205ad9f534ec99baafeccdfec4a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae16323344a459da6f5b021a5d7fcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6068f7b3f5fb4b329f660a2a1605c810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100_000\n",
    "n_examples = n_data\n",
    "n_batches = n_examples // batch_size\n",
    "n_epochs = 20\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    pbar = tqdm(range(n_batches))\n",
    "    for i in pbar:\n",
    "        tokens = torch.tensor(data[i*batch_size:min((i+1)*batch_size,n_data)], dtype=torch.long).to(device=device)\n",
    "        logits = decoder(encoder(tokens))\n",
    "        loss = F.cross_entropy(logits, tokens, ignore_index=-1)\n",
    "        pbar.set_description(f'loss = {loss.item():.6f}')\n",
    "        loss.backward()\n",
    "        optim_enc.step()\n",
    "        optim_enc.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dbd2bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n",
      "========\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You"
     ]
    }
   ],
   "source": [
    "sample = text[:100]\n",
    "print(sample)\n",
    "tokens = torch.tensor([char_to_token[c] for c in sample], dtype=torch.long).to(device=device)\n",
    "tokens_out = torch.argmax(decoder(encoder(tokens)), dim=-1).cpu().tolist()\n",
    "print('========')\n",
    "for i in tokens_out:\n",
    "    print(token_to_char[i], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a63694bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#params = 0.5899M\n"
     ]
    }
   ],
   "source": [
    "neurons  = { 'embeds': LayerNormNeuron(shape=(n_token, n_embed), use_bias=True, bias_dims={1}, device=device, dtype=dtype) }\n",
    "synapses = {\n",
    "    'attn': AttentionSynapse(n_embed, n_heads, n_proj, beta=beta_attn, device=device, dtype=dtype),\n",
    "    'mem': HopfieldSynapse(n_embed, 4*n_embed, beta=beta_mem, device=device, dtype=dtype)\n",
    "}\n",
    "connections = {\n",
    "    'attn': ['embeds', 'embeds'],\n",
    "    'mem': ['embeds']\n",
    "}\n",
    "model = HAM(neurons, synapses, connections)\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'#params = {n_params/1e6:.4f}M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b3f2f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "optim.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab0c4841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17cbef56b574c359e4ee9288b3925a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "n_examples = n_data\n",
    "n_batches  = n_examples // batch_size\n",
    "n_token = 64\n",
    "\n",
    "pbar = tqdm(range(n_batches))\n",
    "for i in pbar:\n",
    "    starts = np.random.randint(0, n_data-n_token, size=(batch_size,))\n",
    "    tokens = torch.tensor(np.array([data[s:s+n_token] for s in starts]), dtype=torch.long).to(device)\n",
    "    embeds = encoder(tokens)\n",
    "    xs = model.init_states(\n",
    "        batch_size=batch_size,\n",
    "        values={ 'embeds': embeds.requires_grad_() },\n",
    "        requires_grad=True,\n",
    "        device=device,\n",
    "        dtype=dtype\n",
    "    )\n",
    "    gs = model.activations(xs)\n",
    "    grads, energy = model.dEdg(xs, gs, create_graph=True, return_energy=True)\n",
    "    grad_loss = torch.cat([torch.norm(g.view(g.shape[0], -1), dim=1, keepdim=True) for g in grads.values()], dim=1).mean(dim=1)\n",
    "    loss = torch.mean(grad_loss + 0.00001*energy)\n",
    "    \n",
    "    mean_grad_loss = torch.mean(grad_loss).item()\n",
    "    mean_energy = torch.mean(energy).item()\n",
    "    pbar.set_description(f'grad loss = {mean_grad_loss:.4f}, energy = {mean_energy:.4f}, loss = {loss.item():.4f}')\n",
    "    \n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad(set_to_none=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3adebc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9684a38e29480db62d3cf8f7a663d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = '''ANTONIO:\n",
    "Do you not hear me speak?\n",
    "\n",
    "SEBASTIAN:\n",
    "'''\n",
    "\n",
    "model.neurons['embeds'].allow_variable_input = True\n",
    "\n",
    "all_tokens = [char_to_token[c] for c in text]\n",
    "response_length = 64\n",
    "pbar = tqdm(range(response_length))\n",
    "\n",
    "for i in pbar:\n",
    "    \n",
    "    tokens = all_tokens[-min(len(all_tokens), n_token-1):]\n",
    "    tokens.append(0)\n",
    "    tokens = torch.tensor(tokens, dtype=torch.long).to(device).view(1, -1)\n",
    "    embeds = encoder(tokens)\n",
    "    embeds[:,-1,:] = 0.0\n",
    "    \n",
    "    xs = model.init_states(\n",
    "        batch_size=1,\n",
    "        values={ 'embeds': embeds.requires_grad_() },\n",
    "        requires_grad=True,\n",
    "        device=device,\n",
    "        dtype=dtype\n",
    "    )\n",
    "    gs = model.activations(xs)\n",
    "    xs, gs = model.energy_descent(xs, gs, max_iter=1000, tol=1e-4, create_graph=False)\n",
    "    logits = decoder(xs['embeds'][:,-1,:])\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    all_tokens.append(torch.argmax(probs.flatten()).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0af70802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTONIO:\n",
      "Do you not hear me speak?\n",
      "\n",
      "SEBASTIAN:\n",
      "-N.3LLL!!L!!LLL3!!GzI!!!!!!X!XRRR!!!!!!T!!!Rp!!,ppp!!!!!!!!!Is;T"
     ]
    }
   ],
   "source": [
    "for i in all_tokens:\n",
    "    print(token_to_char[i], end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
